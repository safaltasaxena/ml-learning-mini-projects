# ğŸ“‰ Gradient Descent â€“ From Scratch Implementation  

ğŸ“Œ A Machine Learning mini project demonstrating **Gradient Descent**
implemented **from scratch using NumPy** to fit a linear regression model.

---

## ğŸ“– About  
This project focuses on understanding how **Gradient Descent** works internally.
Instead of using any ML library, the algorithm is implemented manually to learn
the optimal values of **slope (m)** and **intercept (b)** by minimizing the
**Mean Squared Error (MSE)**.

---

## ğŸ“Š Dataset  
The project uses a simple numeric dataset:
- **Input (x):** `[1, 2, 3, 4, 5]`  
- **Output (y):** `[5, 7, 9, 11, 13]`

This represents a linear relationship used to demonstrate convergence.

---

## âœ¨ Concepts Covered  
- ğŸ“ Linear Regression  
- ğŸ“‰ Gradient Descent optimization  
- ğŸ” Iterative parameter updates  
- âš¡ Learning rate  
- ğŸ§® Mean Squared Error (MSE)  
- ğŸ§  Convergence intuition  

---

## ğŸ› ï¸ Approach  
1. Initialize slope (`m`) and intercept (`b`) to zero  
2. Predict output values using current parameters  
3. Compute gradients with respect to `m` and `b`  
4. Update parameters using learning rate  
5. Calculate loss using Mean Squared Error  
6. Repeat for multiple iterations until error decreases  

---

## â–¶ï¸ Usage  
1. ğŸ“¥ Clone the repository  
2. ğŸ““ Open the notebook in **Google Colab** or **Jupyter Notebook**  
3. â–¶ï¸ Run all cells to observe:
   - Parameter updates (`m` and `b`)  
   - Decreasing cost after each iteration  

---

## ğŸ§  Model  
- Optimization Algorithm: **Gradient Descent**  
- Parameters learned: `m` (slope), `b` (intercept)  
- Loss function: **Mean Squared Error**

---

## ğŸ“ˆ Results  
The cost decreases with each iteration, showing that Gradient Descent
successfully minimizes error and converges toward optimal parameters.

---

ğŸš€ *Part of my Machine Learning mini projects focused on building strong fundamentals!*  
