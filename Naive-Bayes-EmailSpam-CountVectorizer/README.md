# ğŸ“§ Naive Bayes Classifier â€“ Titanic Survival & Spam Detection  

ğŸ“Œ A Machine Learning mini project demonstrating **Naive Bayes Classification**
on both **numerical data** and **text data**, covering real-world use cases.

---

## ğŸ“– About  
This project explores the **Naive Bayes algorithm** using two different datasets:

1ï¸âƒ£ **Titanic Survival Prediction** using **Gaussian Naive Bayes**  
2ï¸âƒ£ **Spam Email Detection** using **Multinomial Naive Bayes**

The project highlights how different Naive Bayes variants are used depending on
the **nature of the data**.

---

## ğŸ“Š Datasets Used  

### ğŸš¢ Titanic Dataset (`Titanic-Dataset.csv`)
Features:
- ğŸ‚ Age  
- ğŸš» Sex *(categorical)*  
- ğŸ’° Fare  
- ğŸ¯ Target: Survived (0 or 1)

Irrelevant features are dropped and missing values are handled before training.

---

### ğŸ“§ Spam Dataset (`spam.csv`)
Features:
- âœ‰ï¸ Message (text data)  
- ğŸ¯ Target: Spam (1) / Ham (0)

---

## âœ¨ Concepts Covered  
- ğŸ“ Naive Bayes algorithm  
- ğŸ“Š **Gaussian Naive Bayes** for numerical data  
- ğŸ“¨ **Multinomial Naive Bayes** for text classification  
- ğŸ”¤ Dummy variable encoding  
- ğŸ§¹ Handling missing values  
- ğŸ§  Probability-based classification  
- ğŸ§¾ Text vectorization using **CountVectorizer**  
- ğŸ”— ML Pipelines using `sklearn`

---

## ğŸ› ï¸ Approach  

### ğŸš¢ Titanic Survival Prediction
1. Drop irrelevant features  
2. Convert categorical variables into numeric form  
3. Handle missing values using mean imputation  
4. Split data into training and testing sets  
5. Train **Gaussian Naive Bayes** model  
6. Evaluate predictions and probabilities  

---

### ğŸ“§ Spam Email Detection
1. Convert labels into binary values (spam / ham)  
2. Split dataset into training and testing sets  
3. Transform text data using **CountVectorizer**  
4. Train **Multinomial Naive Bayes** model  
5. Predict spam emails  
6. Simplify workflow using **Pipeline**

---

## â–¶ï¸ Usage  
1. ğŸ“¥ Clone the repository  
2. ğŸ““ Open the notebook in **Google Colab** or **Jupyter Notebook**  
3. â–¶ï¸ Run all cells to:
   - Train Naive Bayes models  
   - Predict outcomes  
   - Evaluate model accuracy  

---

## ğŸ§  Models Used  
- **GaussianNB** â†’ Numerical features (Titanic dataset)  
- **MultinomialNB** â†’ Text data (Spam detection)

---

## ğŸ“ˆ Results  
- Gaussian Naive Bayes successfully predicts Titanic survival probabilities  
- Multinomial Naive Bayes accurately classifies spam and non-spam emails  
- Pipelines simplify preprocessing and model training  

---

ğŸš€ *Part of my Machine Learning mini projects focused on building strong fundamentals!*  
